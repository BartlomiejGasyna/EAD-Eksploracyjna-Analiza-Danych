{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "def score_dataset(x_train, x_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('melb_data.csv')\n",
    "\n",
    "missing_values_count = df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Jakie oceny zostały uzyskane dla następujących strategii usuwania/uzupełniania danych:\n",
    "\n",
    "a) usunięcie wierszy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188354.82856287423\n"
     ]
    }
   ],
   "source": [
    "# czyszczenie danych\n",
    "train_df_cleaned = train_df.dropna()\n",
    "test_df_cleaned = test_df.dropna()\n",
    "\n",
    "cols_x = train_df_cleaned.select_dtypes(include=[np.number]).columns.difference(['Price'])  # wybiera tylko kolumny z wartosciami numerycznymi, za wyjątkiem kolumny z wartością referencyjną - wejście do klasyfikatora\n",
    "cols_y = 'Price'  # - wyjście z klasyfikatora\n",
    "print(score_dataset(train_df_cleaned[cols_x], test_df_cleaned[cols_x], train_df_cleaned[cols_y], test_df_cleaned[cols_y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) usunięcie kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196311.7920648613\n"
     ]
    }
   ],
   "source": [
    "# czyszczenie danych\n",
    "train_df_cleaned = train_df.dropna(axis=1)\n",
    "test_df_cleaned = test_df.dropna(axis=1)\n",
    "\n",
    "cols_x = train_df_cleaned.select_dtypes(include=[np.number]).columns.difference(['Price'])  # wybiera tylko kolumny z wartosciami numerycznymi, za wyjątkiem kolumny z wartością referencyjną - wejście do klasyfikatora\n",
    "cols_y = 'Price'  # - wyjście z klasyfikatora\n",
    "print(score_dataset(train_df_cleaned[cols_x], test_df_cleaned[cols_x], train_df_cleaned[cols_y], test_df_cleaned[cols_y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) uzupełnienie braków 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188226.58769531525\n"
     ]
    }
   ],
   "source": [
    "# czyszczenie danych\n",
    "train_df_cleaned = train_df.fillna(0)\n",
    "test_df_cleaned = test_df.fillna(0)\n",
    "\n",
    "cols_x = train_df_cleaned.select_dtypes(include=[np.number]).columns.difference(['Price'])  # wybiera tylko kolumny z wartosciami numerycznymi, za wyjątkiem kolumny z wartością referencyjną - wejście do klasyfikatora\n",
    "cols_y = 'Price'  # - wyjście z klasyfikatora\n",
    "print(score_dataset(train_df_cleaned[cols_x], test_df_cleaned[cols_x], train_df_cleaned[cols_y], test_df_cleaned[cols_y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) uzupełnienie braków wartością sąsiednią"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192773.70847569956\n"
     ]
    }
   ],
   "source": [
    "# czyszczenie danych\n",
    "train_df_cleaned = train_df.fillna(method='bfill', axis=0).fillna(0)\n",
    "test_df_cleaned = test_df.fillna(method='bfill', axis=0).fillna(0)\n",
    "\n",
    "cols_x = train_df_cleaned.select_dtypes(include=[np.number]).columns.difference(['Price'])  # wybiera tylko kolumny z wartosciami numerycznymi, za wyjątkiem kolumny z wartością referencyjną - wejście do klasyfikatora\n",
    "cols_y = 'Price'  # - wyjście z klasyfikatora\n",
    "print(score_dataset(train_df_cleaned[cols_x], test_df_cleaned[cols_x], train_df_cleaned[cols_y], test_df_cleaned[cols_y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) uzupełnienie braków medianą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188225.78676622786\n"
     ]
    }
   ],
   "source": [
    "# czyszczenie danych\n",
    "train_df_cleaned = train_df.fillna(train_df.median(numeric_only=True))\n",
    "test_df_cleaned = test_df.fillna(test_df.median(numeric_only=True))\n",
    "\n",
    "cols_x = train_df_cleaned.select_dtypes(include=[np.number]).columns.difference(['Price'])  # wybiera tylko kolumny z wartosciami numerycznymi, za wyjątkiem kolumny z wartością referencyjną - wejście do klasyfikatora\n",
    "cols_y = 'Price'  # - wyjście z klasyfikatora\n",
    "print(score_dataset(train_df_cleaned[cols_x], test_df_cleaned[cols_x], train_df_cleaned[cols_y], test_df_cleaned[cols_y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) dodatnie dnia tygodnia kiedy nastąpiła sprzedaż"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188589.44182864457\n"
     ]
    }
   ],
   "source": [
    "train_df_cleaned = train_df.fillna(train_df.median(numeric_only=True)).copy()\n",
    "test_df_cleaned = test_df.fillna(test_df.median(numeric_only=True)).copy()\n",
    "\n",
    "train_df_cleaned['Day of week'] = pd.to_datetime(train_df.loc[:, \"Date\"], dayfirst=True).dt.dayofweek\n",
    "test_df_cleaned['Day of week'] = pd.to_datetime(test_df.loc[:, \"Date\"], dayfirst=True).dt.dayofweek\n",
    "\n",
    "cols_x = train_df_cleaned.select_dtypes(include=[np.number]).columns.difference(['Price'])  # wybiera tylko kolumny z wartosciami numerycznymi, za wyjątkiem kolumny z wartością referencyjną - wejście do klasyfikatora\n",
    "cols_y = 'Price'  # - wyjście z klasyfikatora\n",
    "print(score_dataset(train_df_cleaned[cols_x], test_df_cleaned[cols_x], train_df_cleaned[cols_y], test_df_cleaned[cols_y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) dodanie nowej cechy (np. CouncilArea) za pomocą LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188082.05119478423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Make copy to avoid changing original data \n",
    "train_df_cleaned = train_df.fillna(train_df.median(numeric_only=True)).copy()\n",
    "test_df_cleaned = test_df.fillna(test_df.median(numeric_only=True)).copy()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "col='CouncilArea'\n",
    "\n",
    "label_encoder.fit(df[col])\n",
    "\n",
    "train_df_cleaned[col] = label_encoder.transform(train_df_cleaned[col])\n",
    "test_df_cleaned[col] = label_encoder.transform(test_df_cleaned[col])\n",
    "\n",
    "\n",
    "cols_x = train_df_cleaned.select_dtypes(include=[np.number]).columns.difference(['Price'])  # wybiera tylko kolumny z wartosciami numerycznymi, za wyjątkiem kolumny z wartością referencyjną - wejście do klasyfikatora\n",
    "cols_y = 'Price'  # - wyjście z klasyfikatora\n",
    "print(score_dataset(train_df_cleaned[cols_x], test_df_cleaned[cols_x], train_df_cleaned[cols_y], test_df_cleaned[cols_y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) dodanie nowej cechy (np. CouncilArea) za pomocą BinaryEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195773.68117271797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "    \n",
    "\n",
    "train_df_cleaned = train_df.fillna(train_df.median(numeric_only=True)).copy()\n",
    "test_df_cleaned = test_df.fillna(test_df.median(numeric_only=True)).copy()\n",
    "\n",
    "col='CouncilArea'\n",
    "df_copy = df.copy().fillna(df[col].mode()[0]).replace('Unavailable', 'Unknown')\n",
    "\n",
    "train_df_cleaned = train_df.fillna(train_df['CouncilArea'].mode()[0]).replace('Unavailable', 'Unknown').copy()\n",
    "test_df_cleaned = test_df.fillna(test_df['CouncilArea'].mode()[0]).replace('Unavailable', 'Unknown').copy()\n",
    "\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "\n",
    "\n",
    "label_binarizer.fit(df_copy[col])\n",
    "\n",
    "train_df_cleaned[col] = label_binarizer.transform(train_df_cleaned[col])\n",
    "test_df_cleaned[col] = label_binarizer.transform(test_df_cleaned[col])\n",
    "\n",
    "\n",
    "cols_x = train_df_cleaned.select_dtypes(include=[np.number]).columns.difference(['Price'])  # wybiera tylko kolumny z wartosciami numerycznymi, za wyjątkiem kolumny z wartością referencyjną - wejście do klasyfikatora\n",
    "cols_y = 'Price'  # - wyjście z klasyfikatora\n",
    "print(score_dataset(train_df_cleaned[cols_x], test_df_cleaned[cols_x], train_df_cleaned[cols_y], test_df_cleaned[cols_y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Spróbuj odpowiedzieć na pytanie: które podejście/podejścia wydają się być najbardziej obiecujące w odniesieniu do estymacji cen nieruchomości (w odniesieniu do uzupełniania braków w poszczególnych kolumnach oraz tworzenia nowych cech bazujących na zmiennych nominalnych?\n",
    "\n",
    "\n",
    "Podeściami które najbardziej rokują na poprawienie estymacji ceny nieruchomości jest połączenie uzupełnienia pustych wartości medianą lub wartością średnią oraz dodanie nowych cech, na przykład odpowiadających za rejon (Council Area). Mimo niewielkiej poprawy wyników, wart byłoby wprowadzić analizę istotności cech, tak aby zredukować wymiarowość zbioru, być może wtedy okaże się że zakodowane dane o rejonie są istotne, a uda nam się zredukować kolumny mniej istotne, co pozytywnie wpłynie na wynik."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
